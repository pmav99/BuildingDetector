{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "In this notebook, I'm going to try getting rid of the template matching step of my building finder and instead just have a sliding window that checks to see if there are roofs in each window. Doing it this way (with constant candidate patch sizes), I can also use the built-in HOG features.\n",
    "\n",
    "The first step will be to grab a bunch of image samples and pull out roof (positive) and nonroof (negative) training examples. Hopefully we can get a somewhat balanced training set.\n",
    "\n",
    "The next step will be to get a set of representative images randomly sampled from the DHS locations and to try to classify each window within them. In this step, it will be useful to save the image patches classified as roofs and nonroofs in separate folders so that we can identify cases where misclassification occurred. We can then add these hard cases to the training set and hopefully improve our classification algorithm.\n",
    "\n",
    "We can repeat this process until we (hopefully) get a good image patch roof/nonroof classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn import ensemble\n",
    "import time\n",
    "import urllib\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from features import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 2 images from DHS cell 100498 in 0.644288063049 seconds.\n",
      "Sampled 2 images from DHS cell 101916 in 0.662126064301 seconds.\n",
      "Sampled 2 images from DHS cell 101940 in 0.657086133957 seconds.\n",
      "Sampled 2 images from DHS cell 101946 in 0.700767040253 seconds.\n",
      "Sampled 2 images from DHS cell 101976 in 0.619593143463 seconds.\n",
      "Sampled 2 images from DHS cell 103383 in 0.619624137878 seconds.\n",
      "Sampled 2 images from DHS cell 104103 in 0.707693815231 seconds.\n",
      "Sampled 2 images from DHS cell 106271 in 0.767592906952 seconds.\n",
      "Sampled 2 images from DHS cell 106977 in 0.627737045288 seconds.\n",
      "Sampled 2 images from DHS cell 106991 in 0.647021055222 seconds.\n",
      "Sampled 2 images from DHS cell 109148 in 0.629818201065 seconds.\n",
      "Sampled 2 images from DHS cell 110577 in 0.662018060684 seconds.\n",
      "Sampled 2 images from DHS cell 110578 in 0.668612003326 seconds.\n",
      "Sampled 2 images from DHS cell 111296 in 0.645262002945 seconds.\n",
      "Sampled 2 images from DHS cell 111297 in 0.653151035309 seconds.\n",
      "Sampled 2 images from DHS cell 112736 in 0.785283088684 seconds.\n",
      "Sampled 2 images from DHS cell 119239 in 0.482118844986 seconds.\n",
      "Sampled 2 images from DHS cell 119959 in 0.492962121964 seconds.\n",
      "Sampled 2 images from DHS cell 123511 in 0.648219108582 seconds.\n",
      "Sampled 2 images from DHS cell 123560 in 0.350080013275 seconds.\n",
      "Sampled 2 images from DHS cell 124259 in 0.702110052109 seconds.\n",
      "Sampled 2 images from DHS cell 124979 in 0.653960943222 seconds.\n",
      "Sampled 2 images from DHS cell 126427 in 0.490828037262 seconds.\n",
      "Sampled 2 images from DHS cell 127100 in 0.586359024048 seconds.\n",
      "Sampled 2 images from DHS cell 127141 in 0.623165845871 seconds.\n",
      "Sampled 2 images from DHS cell 127859 in 0.693773031235 seconds.\n",
      "Sampled 2 images from DHS cell 127874 in 0.622937917709 seconds.\n",
      "Sampled 2 images from DHS cell 127875 in 0.636291027069 seconds.\n",
      "Sampled 2 images from DHS cell 128594 in 0.646084070206 seconds.\n",
      "Sampled 2 images from DHS cell 128595 in 0.65420293808 seconds.\n",
      "Sampled 2 images from DHS cell 129313 in 0.703329086304 seconds.\n",
      "Sampled 2 images from DHS cell 130746 in 0.616409063339 seconds.\n",
      "Sampled 2 images from DHS cell 135740 in 0.379940986633 seconds.\n",
      "Sampled 2 images from DHS cell 135744 in 0.495136976242 seconds.\n",
      "Sampled 2 images from DHS cell 136453 in 0.60826086998 seconds.\n",
      "Sampled 2 images from DHS cell 136454 in 0.656040906906 seconds.\n",
      "Sampled 2 images from DHS cell 136455 in 0.594815015793 seconds.\n",
      "Sampled 2 images from DHS cell 136456 in 0.717360019684 seconds.\n",
      "Sampled 2 images from DHS cell 136457 in 0.352020025253 seconds.\n",
      "Sampled 2 images from DHS cell 137152 in 0.637823104858 seconds.\n",
      "Sampled 2 images from DHS cell 137157 in 0.472831964493 seconds.\n",
      "Sampled 2 images from DHS cell 137172 in 0.433724880219 seconds.\n",
      "Sampled 2 images from DHS cell 137173 in 0.504807949066 seconds.\n",
      "Sampled 2 images from DHS cell 137174 in 0.695577144623 seconds.\n",
      "Sampled 2 images from DHS cell 137175 in 0.654937028885 seconds.\n",
      "Sampled 2 images from DHS cell 137176 in 0.641572952271 seconds.\n",
      "Sampled 2 images from DHS cell 137177 in 0.613085031509 seconds.\n",
      "Sampled 2 images from DHS cell 137879 in 0.66614317894 seconds.\n",
      "Sampled 2 images from DHS cell 137880 in 0.599185943604 seconds.\n",
      "Sampled 2 images from DHS cell 137892 in 0.675820112228 seconds.\n",
      "Sampled 2 images from DHS cell 137893 in 0.519021034241 seconds.\n",
      "Sampled 2 images from DHS cell 137894 in 0.671730041504 seconds.\n",
      "Sampled 2 images from DHS cell 137895 in 0.704555034637 seconds.\n",
      "Sampled 2 images from DHS cell 137896 in 0.662702083588 seconds.\n",
      "Sampled 2 images from DHS cell 138597 in 0.63392996788 seconds.\n",
      "Sampled 2 images from DHS cell 138599 in 0.628733873367 seconds.\n",
      "Sampled 2 images from DHS cell 138600 in 0.616568088531 seconds.\n",
      "Sampled 2 images from DHS cell 138602 in 0.601619005203 seconds.\n",
      "Sampled 2 images from DHS cell 138611 in 0.378769874573 seconds.\n",
      "Sampled 2 images from DHS cell 138612 in 0.547107934952 seconds.\n",
      "Sampled 2 images from DHS cell 138613 in 0.589354991913 seconds.\n",
      "Sampled 2 images from DHS cell 138614 in 0.641673088074 seconds.\n",
      "Sampled 2 images from DHS cell 138615 in 0.638368844986 seconds.\n",
      "Sampled 2 images from DHS cell 139317 in 0.674830198288 seconds.\n",
      "Sampled 2 images from DHS cell 139326 in 0.79617190361 seconds.\n",
      "Sampled 2 images from DHS cell 139327 in 0.643947124481 seconds.\n",
      "Sampled 2 images from DHS cell 139328 in 0.731018066406 seconds.\n",
      "Sampled 2 images from DHS cell 139329 in 0.749621152878 seconds.\n",
      "Sampled 2 images from DHS cell 139332 in 0.358294010162 seconds.\n",
      "Sampled 2 images from DHS cell 139333 in 0.502537965775 seconds.\n",
      "Sampled 2 images from DHS cell 139336 in 0.65752696991 seconds.\n",
      "Sampled 2 images from DHS cell 140030 in 0.521245956421 seconds.\n",
      "Sampled 2 images from DHS cell 140047 in 0.634850025177 seconds.\n",
      "Sampled 2 images from DHS cell 140048 in 0.668102025986 seconds.\n",
      "Sampled 2 images from DHS cell 140049 in 0.655143976212 seconds.\n",
      "Sampled 2 images from DHS cell 140051 in 0.677634954453 seconds.\n",
      "Sampled 2 images from DHS cell 140750 in 0.664927005768 seconds.\n",
      "Sampled 2 images from DHS cell 140769 in 0.63295507431 seconds.\n",
      "Sampled 2 images from DHS cell 140770 in 0.615513086319 seconds.\n",
      "Sampled 2 images from DHS cell 140771 in 0.673005104065 seconds.\n",
      "Sampled 2 images from DHS cell 140773 in 0.516107082367 seconds.\n",
      "Sampled 2 images from DHS cell 140774 in 0.607658863068 seconds.\n",
      "Sampled 2 images from DHS cell 141489 in 0.542447090149 seconds.\n",
      "Sampled 2 images from DHS cell 141490 in 0.668267011642 seconds.\n",
      "Sampled 2 images from DHS cell 142210 in 0.620579004288 seconds.\n",
      "Sampled 2 images from DHS cell 142935 in 0.715808153152 seconds.\n",
      "Sampled 2 images from DHS cell 142936 in 0.635113954544 seconds.\n",
      "Sampled 2 images from DHS cell 142946 in 0.645241975784 seconds.\n",
      "Sampled 2 images from DHS cell 142998 in 0.66760802269 seconds.\n",
      "Sampled 2 images from DHS cell 143613 in 0.515616893768 seconds.\n",
      "Sampled 2 images from DHS cell 143654 in 0.665323019028 seconds.\n",
      "Sampled 2 images from DHS cell 143666 in 0.631470918655 seconds.\n",
      "Sampled 2 images from DHS cell 143668 in 0.647295951843 seconds.\n",
      "Sampled 2 images from DHS cell 144379 in 0.657866001129 seconds.\n",
      "Sampled 2 images from DHS cell 145096 in 0.656394958496 seconds.\n",
      "Sampled 2 images from DHS cell 145816 in 0.62482881546 seconds.\n",
      "Sampled 2 images from DHS cell 147254 in 0.612205982208 seconds.\n",
      "Sampled 2 images from DHS cell 147258 in 0.718086004257 seconds.\n",
      "Sampled 2 images from DHS cell 147271 in 0.657903909683 seconds.\n",
      "Sampled 2 images from DHS cell 147944 in 0.651212930679 seconds.\n",
      "Done. Sampled 200 images total.\n"
     ]
    }
   ],
   "source": [
    "# Import and preview csv data\n",
    "dhs_fn = '../data/IMR1990-2000_NL1992-2012_thresh100.csv'\n",
    "dhs_data = pd.read_csv(dhs_fn)\n",
    "\n",
    "# Samples to take from each location\n",
    "samples = 2\n",
    "# Number of locations to sample from\n",
    "locations = 100\n",
    "\n",
    "# Output image directory\n",
    "out_dir = '../images/forest/samples/'\n",
    "out_csv = '../data/dhs_image_metadata.csv'\n",
    "\n",
    "# Create DataFrame for image metadata\n",
    "image_data = pd.DataFrame(columns=['image', 'cellid', 'cell_lat',\n",
    "                                  'cell_lon', 'lat', 'lon'])\n",
    "\n",
    "# Sampling images from DHS locations\n",
    "for index, row in dhs_data.iterrows():\n",
    "    if index + 1 > locations:\n",
    "        break\n",
    "    \n",
    "    cell_id = int(row['cellid'])\n",
    "    cell_lat = row['lat']\n",
    "    cell_lon = row['lon']\n",
    "    # Sample images\n",
    "    image_data = sample_dhs(image_data, cell_id, cell_lat, cell_lon,\n",
    "                           samples, out_dir)\n",
    "\n",
    "# Save image metadata to csv\n",
    "image_data.set_index('image', inplace=True)\n",
    "image_data.to_csv(out_csv)\n",
    "\n",
    "print 'Done. Sampled {} images total.'.format(samples * locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 31 images in 0.0168931484222 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Rename images first\n",
    "in_dir = '../images/forest/samples/'\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    out_fn = in_dir + str(count) + '.png'\n",
    "    os.rename(image_fn, out_fn)\n",
    "    count += 1\n",
    "t1 = time.time()\n",
    "print 'Renamed {} images in {} seconds.'.format(count, (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have some images, we need to split them up into 81 (9x9) 80x80 pixel patches. Let's write a few functions to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_patch(image, out_fn, x=0, y=0, width=80, height=80):\n",
    "    \"\"\"\n",
    "    This function saves a specified image patch from a image.\n",
    "    :param image: Input 3-channel image\n",
    "    :param out_fn: Filename for output image patch\n",
    "    :param x: Top left x-coordinate of image patch\n",
    "    :param y: Top left y-coordinate of image patch\n",
    "    :param width: Width in pixels of image patch\n",
    "    :param height: Height in pixels of image patch\n",
    "    \"\"\"\n",
    "    patch = image[x:x+width, y:y+width, :]\n",
    "    cv2.imwrite(out_fn, patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_patches(image_fn, out_dir, width=80, height=80):\n",
    "    \"\"\"\n",
    "    This function takes each input image and saves however many image\n",
    "    patches of the specified size as can fit in the original image. \n",
    "    Image patches are offset by half the height and width specified.\n",
    "    :param image_fn: Input image filename\n",
    "    :param out_dir: Folder where image patches will be saved\n",
    "    :param width: Width of each image patch\n",
    "    :param height: Height of each image patch\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_fn)\n",
    "    # Get dimensions of input image\n",
    "    max_x, max_y = image.shape[:2]\n",
    "    # Pull image patches as long as they fit in the image\n",
    "    count = 0\n",
    "    top_left_x = 0\n",
    "    while (top_left_x + (height - 1) < max_x):\n",
    "        top_left_y = 0\n",
    "        while (top_left_y + (width - 1) < max_y):\n",
    "            out_fn = (out_dir + os.path.basename(image_fn)[:-4] + '_' +\n",
    "                      str(count) + '.png')\n",
    "            save_patch(image, out_fn, top_left_x, top_left_y, width,\n",
    "                       height)\n",
    "            count += 1\n",
    "            top_left_y += (width/2)\n",
    "        top_left_x += (height/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we can save 81 patches from any image, let's go through our samples and save 81 patches for each of them to separate into positive and negative training examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved patches for 142 images.\n"
     ]
    }
   ],
   "source": [
    "# Save patches from all sample images\n",
    "in_dir = '../images/forest/samples/'\n",
    "out_dir = '../images/forest/patches/'\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    save_patches(image_fn, out_dir)\n",
    "    count += 1\n",
    "t1 = time.time()\n",
    "print 'Saved patches for {} images in {} seconds.'.format(count,(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 817 images in 3.83475995064 seconds.\n",
      "Copied 1121 images in 3.44424295425 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Rename images first\n",
    "in_dir = '../images/forest/training/roof/'\n",
    "out_dir = '../images/forest/training/new_roof/'\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    out_fn = out_dir + str(count) + '.png'\n",
    "    shutil.copyfile(image_fn, out_fn)\n",
    "    count += 1\n",
    "t1 = time.time()\n",
    "print 'Copied {} images in {} seconds.'.format(count, (t1-t0))\n",
    "# Rename images first\n",
    "in_dir = '../images/forest/training/nonroof/'\n",
    "out_dir = '../images/forest/training/new_nonroof/'\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    out_fn = out_dir + str(count) + '.png'\n",
    "    shutil.copyfile(image_fn, out_fn)\n",
    "    count += 1\n",
    "t1 = time.time()\n",
    "print 'Copied {} images in {} seconds.'.format(count, (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from training examples\n",
    "Ok, now that we've organized those patches into roof and nonroof classes, let's first use the feature extractor functions that we wrote earlier and see how well it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 817 images for roof class.\n",
      "Processed 1121 images for nonroof class.\n",
      "Processed 1938 images total in 178.022072792 seconds.\n"
     ]
    }
   ],
   "source": [
    "sample_dir = '../images/forest/training/'\n",
    "csv_out = '../data/forest_training_data.csv'\n",
    "store_image_data(sample_dir, csv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load those features back into the workspace so that we can use them for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nonroof' 'roof']\n",
      "Got class labels for 1938 training data points.\n",
      "Got feature vectors for 1938 training data points.\n"
     ]
    }
   ],
   "source": [
    "csv_in = '../data/forest_training_data.csv'\n",
    "(features, colors, hogs, mags, labels, label_encoder) = \\\n",
    "                import_image_data(csv_in, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well a random forest classifier does on these training examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mix up the data\n",
    "perm = np.random.permutation(labels.size)\n",
    "features = features[perm]\n",
    "labels = labels[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification accuracy: 0.908675799087\n",
      "Took 0.185886859894 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=50, random_state=0,\n",
    "                                      class_weight='auto')\n",
    "# Training on training examples\n",
    "num_train = 1500\n",
    "clf.fit(features[:num_train], labels[:num_train])\n",
    "accuracy = clf.score(features[num_train:], labels[num_train:])\n",
    "print 'Overall classification accuracy: {}'.format(accuracy)\n",
    "t1 = time.time()\n",
    "print 'Took {} seconds.'.format(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 test examples: 190 positive, 248 negative\n",
      "Predicted: 182 positive, 256 negative.\n",
      "Prediction results:\n",
      "    166 true positive, 16 false positive\n",
      "    232 true negative, 24 false negative\n",
      "Roof accuracy: 0.873684210526\n",
      "Nonroof accuracy: 0.935483870968\n"
     ]
    }
   ],
   "source": [
    "# Figuring out the true/false positive/negative rates\n",
    "y_hat = clf.predict(features[num_train:])\n",
    "y = labels[num_train:]\n",
    "num_test = y_hat.shape[0]\n",
    "positive = sum(y)\n",
    "negative = num_test - positive\n",
    "print '{} test examples: {} positive, {} negative'.format(num_test,\n",
    "                                                     positive, negative)\n",
    "positive_hat = sum(y_hat)\n",
    "negative_hat = num_test - positive_hat\n",
    "print 'Predicted: {} positive, {} negative.'.format(positive_hat,\n",
    "                                                   negative_hat)\n",
    "# Different types of mistakes:\n",
    "# 0 = correct, -1 = false positive, 1 = false negative\n",
    "mistakes = y - y_hat\n",
    "false_neg = mistakes > 0\n",
    "false_pos = mistakes < 0\n",
    "false_neg_count = sum(false_neg)\n",
    "false_pos_count = sum(false_pos)\n",
    "true_pos = positive_hat - false_pos_count\n",
    "true_neg = negative_hat - false_neg_count\n",
    "print 'Prediction results:'\n",
    "print '    {} true positive, {} false positive'.format(true_pos,\n",
    "                                                      false_pos_count)\n",
    "print '    {} true negative, {} false negative'.format(true_neg,\n",
    "                                                      false_neg_count)\n",
    "print 'Roof accuracy: {}'.format(float(true_pos) / positive)\n",
    "print 'Nonroof accuracy: {}'.format(float(true_neg) / negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks extremely promising! Let's get some new random DHS images and try to classify the image patches within them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifier\n",
    "It seems that this might actually result in a good roof detector! Let's get a new set of DHS images and see how it does classifying all the image patches. We can see where it makes mistakes and then add those \"hard\" examples to the training set--hopefully that will improve the classifier going forward.\n",
    "\n",
    "Ok, we've use the code above to get a new set of DHS images. Let's break those up into 81 image patches each and classify each of them, saving them into separate roof and nonroof folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = '../images/forest/samples/'\n",
    "roof_dir = '../images/forest/classify/roof/'\n",
    "nonroof_dir = '../images/forest/classify/nonroof/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train random forest classifier on all training examples\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=50, random_state=0,\n",
    "                                      class_weight='auto')\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying patches in image 1.\n",
      "Classifying patches in image 2.\n",
      "Classifying patches in image 3.\n",
      "Classifying patches in image 4.\n",
      "Classifying patches in image 5.\n",
      "Classifying patches in image 6.\n",
      "Classifying patches in image 7.\n",
      "Classifying patches in image 8.\n",
      "Classifying patches in image 9.\n",
      "Classifying patches in image 10.\n",
      "Classifying patches in image 11.\n",
      "Classifying patches in image 12.\n",
      "Classifying patches in image 13.\n",
      "Classifying patches in image 14.\n",
      "Classifying patches in image 15.\n",
      "Classifying patches in image 16.\n",
      "Classifying patches in image 17.\n",
      "Classifying patches in image 18.\n",
      "Classifying patches in image 19.\n",
      "Classifying patches in image 20.\n",
      "Classifying patches in image 21.\n",
      "Classifying patches in image 22.\n",
      "Classifying patches in image 23.\n",
      "Classifying patches in image 24.\n",
      "Classifying patches in image 25.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b08dccf859f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m                                     axis=0)\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# Classify image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 0 = nonroof, 1 = roof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mnonroof_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/cs.stanford.edu/u/nealjean/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;31m# ensure_2d=False because there are actually unit test checking we fail\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;31m# for 1d.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/cs.stanford.edu/u/nealjean/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[0;32m    350\u001b[0m                              array.ndim)\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/cs.stanford.edu/u/nealjean/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     50\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     51\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 52\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Classify each image patch\n",
    "width = 80\n",
    "height = 80\n",
    "image_count = 0\n",
    "t0 = time.time()\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    # Load in image\n",
    "    image = cv2.imread(image_fn)\n",
    "    image_count += 1\n",
    "    print 'Classifying patches in image {}.'.format(image_count)\n",
    "    # Get dimensions of input image\n",
    "    max_x, max_y = image.shape[:2]\n",
    "    # Pull image patches as long as they fit in the image\n",
    "    count = 0\n",
    "    top_left_x = 0\n",
    "    while (top_left_x + (height - 1) < max_x):\n",
    "        top_left_y = 0\n",
    "        while (top_left_y + (width - 1) < max_y):\n",
    "            # Get feature vector from image patch\n",
    "            patch = image[top_left_x:top_left_x+width,\n",
    "                          top_left_y:top_left_y+width, :]\n",
    "            color = calc_color_hist(patch)\n",
    "            color = color.flatten()\n",
    "            (hog, hog_bins, magnitude_hist, magnitude_bins,\n",
    "             max_magnitude) = compute_hog(patch)\n",
    "            feature = np.concatenate((color, hog, magnitude_hist),\n",
    "                                    axis=0)\n",
    "            # Classify image\n",
    "            predict = clf.predict(feature)[0] # 0 = nonroof, 1 = roof\n",
    "            probs = clf.predict_proba(feature)[0]\n",
    "            nonroof_prob = probs[0]\n",
    "            roof_prob = probs[1]\n",
    "            # Decide where to save image patch\n",
    "            if predict == 1:\n",
    "                out_fn = (roof_dir + os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) + '_' + str(roof_prob) +  '.png')\n",
    "            else:\n",
    "                out_fn = (nonroof_dir + os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) + '_' + str(nonroof_prob) + '.png')\n",
    "            # Save image patch\n",
    "            save_patch(image, out_fn, top_left_x, top_left_y,\n",
    "                           width, height)\n",
    "            count += 1\n",
    "            top_left_y += (width/2)\n",
    "        top_left_x += (height/2)\n",
    "t1 = time.time()\n",
    "print 'Classified image patches for {} images in {} seconds.'.format(\n",
    "                                        image_count, (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this a couple more times to get more hard training examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Writing annotated classified images\n",
    "Our next step will be to save annotated versions of our classified images so that we can visually inspect them to see how well our classifier is doing. Some things that we want to do here are:\n",
    "\n",
    "- Draw bounding boxes around patches identified as roofs\n",
    "- Use non-maximum suppression to keep only the best patch out of overlapping patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Draw all bounding boxes around patches classified as roofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = '../images/forest/samples/'\n",
    "roof_dir = '../images/forest/classify/roof/'\n",
    "nonroof_dir = '../images/forest/classify/nonroof/'\n",
    "annotated_dir = '../images/forest/classify/annotated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train random forest classifier on all training examples\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=50, random_state=0,\n",
    "                                      class_weight='auto')\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying patches in image 1.\n",
      "Classifying patches in image 2.\n",
      "Classifying patches in image 3.\n",
      "Classifying patches in image 4.\n",
      "Classifying patches in image 5.\n",
      "Classifying patches in image 6.\n",
      "Classifying patches in image 7.\n",
      "Classifying patches in image 8.\n",
      "Classifying patches in image 9.\n",
      "Classifying patches in image 10.\n",
      "Classifying patches in image 11.\n",
      "Classifying patches in image 12.\n",
      "Classifying patches in image 13.\n",
      "Classifying patches in image 14.\n",
      "Classifying patches in image 15.\n",
      "Classifying patches in image 16.\n",
      "Classifying patches in image 17.\n",
      "Classified image patches for 17 images in 112.135099173 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Classify each image patch\n",
    "width = 80\n",
    "height = 80\n",
    "image_count = 0\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "annotation_color = (0,255,0) # green\n",
    "t0 = time.time()\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    # Load in image and one to annotate\n",
    "    image = cv2.imread(image_fn)\n",
    "    image_out = cv2.imread(image_fn)\n",
    "    image_count += 1\n",
    "    print 'Classifying patches in image {}.'.format(image_count)\n",
    "    # Get dimensions of input image\n",
    "    max_x, max_y = image.shape[:2]\n",
    "    # Pull image patches as long as they fit in the image\n",
    "    count = 0\n",
    "    top_left_x = 0\n",
    "    while (top_left_x + (height - 1) < max_x):\n",
    "        top_left_y = 0\n",
    "        while (top_left_y + (width - 1) < max_y):\n",
    "            # Get feature vector from image patch\n",
    "            patch = image[top_left_x:top_left_x+height,\n",
    "                          top_left_y:top_left_y+width, :]\n",
    "            color = calc_color_hist(patch)\n",
    "            color = color.flatten()\n",
    "            (hog, hog_bins, magnitude_hist, magnitude_bins,\n",
    "             max_magnitude) = compute_hog(patch)\n",
    "            feature = np.concatenate((color, hog, magnitude_hist),\n",
    "                                    axis=0)\n",
    "            # Classify image patch\n",
    "            predict = clf.predict(feature)[0] # 0 = nonroof, 1 = roof\n",
    "            probs = clf.predict_proba(feature)[0]\n",
    "            nonroof_prob = probs[0]\n",
    "            roof_prob = probs[1]\n",
    "            # Annotate image when patches classified as roofs\n",
    "            if predict == 1:\n",
    "                cv2.putText(image_out, str(roof_prob),\n",
    "                            (top_left_y + height/2, top_left_x + width/2),\n",
    "                            font, 0.5, annotation_color, thickness=1,\n",
    "                            lineType=cv2.CV_AA)\n",
    "                cv2.rectangle(image_out, (top_left_y, top_left_x),\n",
    "                             (top_left_y+height-1, top_left_x+width-1),\n",
    "                             annotation_color)\n",
    "            # Decide where to save image patch\n",
    "            if predict == 1:\n",
    "                out_fn = (roof_dir + str(roof_prob) + '_' +\n",
    "                          os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) +  '.png')\n",
    "            else:\n",
    "                out_fn = (nonroof_dir + str(nonroof_prob) + '_' +\n",
    "                          os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) + '.png')\n",
    "            # Save image patch\n",
    "            save_patch(image, out_fn, top_left_x, top_left_y,\n",
    "                           width, height)\n",
    "            count += 1\n",
    "            top_left_y += (width/2)\n",
    "        top_left_x += (height/2)\n",
    "    # Save annotated image\n",
    "    image_out_fn = annotated_dir + os.path.basename(image_fn)\n",
    "    cv2.imwrite(image_out_fn, image_out)\n",
    "t1 = time.time()\n",
    "print 'Classified image patches for {} images in {} seconds.'.format(\n",
    "                                        image_count, (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adding non-maximum suppression\n",
    "What we should do here is save all the locations and probabilities of the patches classified as roofs within each image. Then at the end, we can choose the maximum probability patches.\n",
    "\n",
    "As a side note, I ran into an issue where Nautilus was no longer displaying preview images, which was really inconvenient for viewing my classification results. The following code deletes old previews so that new ones can be generated:\n",
    "\n",
    "`rm ~/.cache/thumbnails/ -R`\n",
    "\n",
    "Tested and works, thumbnails restored!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = '../images/forest/samples/'\n",
    "roof_dir = '../images/forest/classify/roof/'\n",
    "nonroof_dir = '../images/forest/classify/nonroof/'\n",
    "annotated_dir = '../images/forest/classify/annotated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train random forest classifier on all training examples\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=50, random_state=0,\n",
    "                                      class_weight='auto')\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying patches in image 1.\n",
      "Classifying patches in image 2.\n",
      "Classifying patches in image 3.\n",
      "Classifying patches in image 4.\n",
      "Classifying patches in image 5.\n",
      "Classifying patches in image 6.\n",
      "Classifying patches in image 7.\n",
      "Classifying patches in image 8.\n",
      "Classifying patches in image 9.\n",
      "Classifying patches in image 10.\n",
      "Classifying patches in image 11.\n",
      "Classifying patches in image 12.\n",
      "Classifying patches in image 13.\n",
      "Classifying patches in image 14.\n",
      "Classifying patches in image 15.\n",
      "Classifying patches in image 16.\n",
      "Classifying patches in image 17.\n",
      "Classifying patches in image 18.\n",
      "Classifying patches in image 19.\n",
      "Classifying patches in image 20.\n",
      "Classifying patches in image 21.\n",
      "Classifying patches in image 22.\n",
      "Classifying patches in image 23.\n",
      "Classifying patches in image 24.\n",
      "Classifying patches in image 25.\n",
      "Classifying patches in image 26.\n",
      "Classifying patches in image 27.\n",
      "Classifying patches in image 28.\n",
      "Classifying patches in image 29.\n",
      "Classifying patches in image 30.\n",
      "Classifying patches in image 31.\n",
      "Classified image patches for 31 images in 194.116039991 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Classify each image patch\n",
    "width = 80\n",
    "height = 80\n",
    "image_count = 0\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "annotation_color = (0,255,0) # green\n",
    "t0 = time.time()\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    # Load in image and one to annotate\n",
    "    image = cv2.imread(image_fn)\n",
    "    image_out = cv2.imread(image_fn)\n",
    "    image_count += 1\n",
    "    print 'Classifying patches in image {}.'.format(image_count)\n",
    "    # Get dimensions of input image\n",
    "    max_x, max_y = image.shape[:2]\n",
    "    # Pull image patches as long as they fit in the image\n",
    "    count = 0\n",
    "    top_left_x = 0\n",
    "    # Lists to store locations and probabilities for detected roofs\n",
    "    locations = []\n",
    "    roof_probabilities = []\n",
    "    while (top_left_x + (height - 1) < max_x):\n",
    "        top_left_y = 0\n",
    "        while (top_left_y + (width - 1) < max_y):\n",
    "            # Get feature vector from image patch\n",
    "            patch = image[top_left_x:top_left_x+height,\n",
    "                          top_left_y:top_left_y+width, :]\n",
    "            color = calc_color_hist(patch)\n",
    "            color = color.flatten()\n",
    "            (hog, hog_bins, magnitude_hist, magnitude_bins,\n",
    "             max_magnitude) = compute_hog(patch)\n",
    "            feature = np.concatenate((color, hog, magnitude_hist),\n",
    "                                    axis=0)\n",
    "            # Classify image patch\n",
    "            predict = clf.predict(feature)[0] # 0 = nonroof, 1 = roof\n",
    "            probs = clf.predict_proba(feature)[0]\n",
    "            nonroof_prob = probs[0]\n",
    "            roof_prob = probs[1]\n",
    "            # If classified as a roof, store location and probability\n",
    "            if predict == 1:\n",
    "                locations.append((top_left_x, top_left_y))\n",
    "                roof_probabilities.append(roof_prob)\n",
    "            # Decide where to save image patch\n",
    "            if predict == 1:\n",
    "                out_fn = (roof_dir + str(roof_prob) + '_' +\n",
    "                          os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) +  '.png')\n",
    "            else:\n",
    "                out_fn = (nonroof_dir + str(nonroof_prob) + '_' +\n",
    "                          os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) + '.png')\n",
    "            # Save image patch\n",
    "            save_patch(image, out_fn, top_left_x, top_left_y,\n",
    "                           width, height)\n",
    "            count += 1\n",
    "            top_left_y += (width/2)\n",
    "        top_left_x += (height/2)\n",
    "    # Annotate image with non-maximum suppression\n",
    "    annotate_locs = []\n",
    "    annotate_probs = []\n",
    "    while locations:\n",
    "        max_prob = max(roof_probabilities)\n",
    "        max_ind = roof_probabilities.index(max_prob)\n",
    "        current_prob = roof_probabilities.pop(max_ind)\n",
    "        current_loc = locations.pop(max_ind)\n",
    "        # Check to see if overlapping\n",
    "        overlap = False\n",
    "        for i in range(len(annotate_locs)):\n",
    "            if ((abs(current_loc[0] - annotate_locs[i][0]) < width) and\n",
    "                (abs(current_loc[1] - annotate_locs[i][1]) < height)):\n",
    "                overlap = True\n",
    "        # If not overlapping, annotate and add to annotated list\n",
    "        if not overlap:\n",
    "            cv2.putText(image_out, str(current_prob),\n",
    "                        (current_loc[1] + height/2, current_loc[0] + width/2),\n",
    "                        font, 0.5, annotation_color, thickness=1,\n",
    "                        lineType=cv2.CV_AA)\n",
    "            cv2.rectangle(image_out, (current_loc[1], current_loc[0]),\n",
    "                         (current_loc[1]+height-1, current_loc[0]+width-1),\n",
    "                         annotation_color)\n",
    "            annotate_locs.append(current_loc)\n",
    "            annotate_probs.append(current_prob)\n",
    "    # Save annotated image\n",
    "    image_out_fn = annotated_dir + os.path.basename(image_fn)\n",
    "    cv2.imwrite(image_out_fn, image_out)\n",
    "t1 = time.time()\n",
    "print 'Classified image patches for {} images in {} seconds.'.format(\n",
    "                                        image_count, (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To run overnight (7/31/15)\n",
    "Sample 5 images from each DHS location and classify all the image patches within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1 images from DHS cell 100498 in 0.35134601593 seconds.\n",
      "Sampled 1 images from DHS cell 101916 in 0.294004201889 seconds.\n",
      "Done. Sampled 2 images total.\n",
      "Renamed 2 images in 0.00120711326599 seconds.\n",
      "Classifying patches in image 1.\n",
      "Classifying patches in image 2.\n",
      "Classified image patches for 2 images in 13.3644838333 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Import and preview csv data\n",
    "dhs_fn = '../data/IMR1990-2000_NL1992-2012_thresh100.csv'\n",
    "dhs_data = pd.read_csv(dhs_fn)\n",
    "\n",
    "# Samples to take from each location\n",
    "samples = 5\n",
    "# Number of locations to sample from\n",
    "locations = 150\n",
    "\n",
    "# Output image directory\n",
    "out_dir = '../images/forest/samples/'\n",
    "out_csv = '../data/dhs_image_metadata.csv'\n",
    "\n",
    "# Create DataFrame for image metadata\n",
    "image_data = pd.DataFrame(columns=['image', 'cellid', 'cell_lat',\n",
    "                                  'cell_lon', 'lat', 'lon'])\n",
    "\n",
    "# Sampling images from DHS locations\n",
    "for index, row in dhs_data.iterrows():\n",
    "    if index + 1 > locations:\n",
    "        break\n",
    "    \n",
    "    cell_id = int(row['cellid'])\n",
    "    cell_lat = row['lat']\n",
    "    cell_lon = row['lon']\n",
    "    # Sample images\n",
    "    image_data = sample_dhs(image_data, cell_id, cell_lat, cell_lon,\n",
    "                           samples, out_dir)\n",
    "\n",
    "# Save image metadata to csv\n",
    "image_data.set_index('image', inplace=True)\n",
    "image_data.to_csv(out_csv)\n",
    "\n",
    "print 'Done. Sampled {} images total.'.format(samples * locations)\n",
    "\n",
    "# Rename images first\n",
    "in_dir = '../images/forest/samples/'\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    out_fn = in_dir + str(count) + '.png'\n",
    "    os.rename(image_fn, out_fn)\n",
    "    count += 1\n",
    "t1 = time.time()\n",
    "print 'Renamed {} images in {} seconds.'.format(count, (t1-t0))\n",
    "\n",
    "in_dir = '../images/forest/samples/'\n",
    "roof_dir = '../images/forest/classify/roof/'\n",
    "nonroof_dir = '../images/forest/classify/nonroof/'\n",
    "annotated_dir = '../images/forest/classify/annotated/'\n",
    "\n",
    "# Train random forest classifier on all training examples\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=50, random_state=0,\n",
    "                                      class_weight='auto')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# Classify each image patch\n",
    "width = 80\n",
    "height = 80\n",
    "image_count = 0\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "annotation_color = (0,255,0) # green\n",
    "t0 = time.time()\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    # Load in image and one to annotate\n",
    "    image = cv2.imread(image_fn)\n",
    "    image_out = cv2.imread(image_fn)\n",
    "    image_count += 1\n",
    "    print 'Classifying patches in image {}.'.format(image_count)\n",
    "    # Get dimensions of input image\n",
    "    max_x, max_y = image.shape[:2]\n",
    "    # Pull image patches as long as they fit in the image\n",
    "    count = 0\n",
    "    top_left_x = 0\n",
    "    # Lists to store locations and probabilities for detected roofs\n",
    "    locations = []\n",
    "    roof_probabilities = []\n",
    "    while (top_left_x + (height - 1) < max_x):\n",
    "        top_left_y = 0\n",
    "        while (top_left_y + (width - 1) < max_y):\n",
    "            # Get feature vector from image patch\n",
    "            patch = image[top_left_x:top_left_x+height,\n",
    "                          top_left_y:top_left_y+width, :]\n",
    "            color = calc_color_hist(patch)\n",
    "            color = color.flatten()\n",
    "            (hog, hog_bins, magnitude_hist, magnitude_bins,\n",
    "             max_magnitude) = compute_hog(patch)\n",
    "            feature = np.concatenate((color, hog, magnitude_hist),\n",
    "                                    axis=0)\n",
    "            # Classify image patch\n",
    "            predict = clf.predict(feature)[0] # 0 = nonroof, 1 = roof\n",
    "            probs = clf.predict_proba(feature)[0]\n",
    "            nonroof_prob = probs[0]\n",
    "            roof_prob = probs[1]\n",
    "            # If classified as a roof, store location and probability\n",
    "            if predict == 1:\n",
    "                locations.append((top_left_x, top_left_y))\n",
    "                roof_probabilities.append(roof_prob)\n",
    "            # Decide where to save image patch\n",
    "            if predict == 1:\n",
    "                out_fn = (roof_dir + str(roof_prob) + '_' +\n",
    "                          os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) +  '.png')\n",
    "            else:\n",
    "                out_fn = (nonroof_dir + str(nonroof_prob) + '_' +\n",
    "                          os.path.basename(image_fn)[:-4] +\n",
    "                          '_' + str(count) + '.png')\n",
    "            # Save image patch\n",
    "            save_patch(image, out_fn, top_left_x, top_left_y,\n",
    "                           width, height)\n",
    "            count += 1\n",
    "            top_left_y += (width/2)\n",
    "        top_left_x += (height/2)\n",
    "    # Annotate image with non-maximum suppression\n",
    "    annotate_locs = []\n",
    "    annotate_probs = []\n",
    "    while locations:\n",
    "        max_prob = max(roof_probabilities)\n",
    "        max_ind = roof_probabilities.index(max_prob)\n",
    "        current_prob = roof_probabilities.pop(max_ind)\n",
    "        current_loc = locations.pop(max_ind)\n",
    "        # Check to see if overlapping\n",
    "        overlap = False\n",
    "        for i in range(len(annotate_locs)):\n",
    "            if ((abs(current_loc[0] - annotate_locs[i][0]) < width) and\n",
    "                (abs(current_loc[1] - annotate_locs[i][1]) < height)):\n",
    "                overlap = True\n",
    "        # If not overlapping, annotate and add to annotated list\n",
    "        if not overlap:\n",
    "            cv2.putText(image_out, str(current_prob),\n",
    "                        (current_loc[1] + height/2, current_loc[0] + width/2),\n",
    "                        font, 0.5, annotation_color, thickness=1,\n",
    "                        lineType=cv2.CV_AA)\n",
    "            cv2.rectangle(image_out, (current_loc[1], current_loc[0]),\n",
    "                         (current_loc[1]+height-1, current_loc[0]+width-1),\n",
    "                         annotation_color)\n",
    "            annotate_locs.append(current_loc)\n",
    "            annotate_probs.append(current_prob)\n",
    "    # Save annotated image\n",
    "    image_out_fn = annotated_dir + os.path.basename(image_fn)\n",
    "    cv2.imwrite(image_out_fn, image_out)\n",
    "t1 = time.time()\n",
    "print 'Classified image patches for {} images in {} seconds.'.format(\n",
    "                                        image_count, (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

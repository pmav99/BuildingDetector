{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New DHS images\n",
    "In this notebook, I will download a new set of DHS images. We'll see how well our current two-step classifier works on this new test set. We can also use these new images to collect more training data for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing DHS data\n",
    "First, let's import the data created earlier when we were examining the correlation between nightlights and infant mortality rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cellid</th>\n",
       "      <th>birthsAfter</th>\n",
       "      <th>birthsBefore</th>\n",
       "      <th>dIMR</th>\n",
       "      <th>dNL</th>\n",
       "      <th>imrAfter</th>\n",
       "      <th>imrBefore</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>nlAfter</th>\n",
       "      <th>nlBefore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 100498</td>\n",
       "      <td> 891</td>\n",
       "      <td> 1392</td>\n",
       "      <td>  6.864624</td>\n",
       "      <td> 0</td>\n",
       "      <td>  37.037037</td>\n",
       "      <td> 30.172413</td>\n",
       "      <td>-20.25</td>\n",
       "      <td> 28.75</td>\n",
       "      <td> 5</td>\n",
       "      <td> 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 101916</td>\n",
       "      <td> 173</td>\n",
       "      <td>  350</td>\n",
       "      <td>-33.955410</td>\n",
       "      <td> 0</td>\n",
       "      <td>  28.901733</td>\n",
       "      <td> 62.857143</td>\n",
       "      <td>-19.25</td>\n",
       "      <td> 17.75</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 101940</td>\n",
       "      <td> 187</td>\n",
       "      <td>  292</td>\n",
       "      <td> 18.148853</td>\n",
       "      <td> 0</td>\n",
       "      <td>  69.518715</td>\n",
       "      <td> 51.369862</td>\n",
       "      <td>-19.25</td>\n",
       "      <td> 29.75</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 101946</td>\n",
       "      <td> 162</td>\n",
       "      <td>  146</td>\n",
       "      <td> 48.114319</td>\n",
       "      <td> 1</td>\n",
       "      <td> 123.456787</td>\n",
       "      <td> 75.342468</td>\n",
       "      <td>-19.25</td>\n",
       "      <td> 32.75</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 101976</td>\n",
       "      <td> 402</td>\n",
       "      <td>  295</td>\n",
       "      <td>-51.066700</td>\n",
       "      <td> 3</td>\n",
       "      <td>   9.950249</td>\n",
       "      <td> 61.016949</td>\n",
       "      <td>-19.25</td>\n",
       "      <td> 47.75</td>\n",
       "      <td> 4</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cellid  birthsAfter  birthsBefore       dIMR  dNL    imrAfter  imrBefore  \\\n",
       "0  100498          891          1392   6.864624    0   37.037037  30.172413   \n",
       "1  101916          173           350 -33.955410    0   28.901733  62.857143   \n",
       "2  101940          187           292  18.148853    0   69.518715  51.369862   \n",
       "3  101946          162           146  48.114319    1  123.456787  75.342468   \n",
       "4  101976          402           295 -51.066700    3    9.950249  61.016949   \n",
       "\n",
       "     lat    lon  nlAfter  nlBefore  \n",
       "0 -20.25  28.75        5         5  \n",
       "1 -19.25  17.75        1         1  \n",
       "2 -19.25  29.75        1         1  \n",
       "3 -19.25  32.75        2         1  \n",
       "4 -19.25  47.75        4         1  \n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and preview csv data\n",
    "dhs_fn = '../data/IMR1990-2000_NL1992-2012_thresh100.csv'\n",
    "dhs_data = pd.read_csv(dhs_fn)\n",
    "dhs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample images from each DHS cell\n",
    "Next, we want to sample images from each half-degree DHS cell using the Goole Static Maps API. Ideally, we want to be able to get an arbitrary number of images from each cell and store data about the image in a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_image(out_fn, lat, lon, height=400, width=400, zoom=19):\n",
    "    \"\"\"\n",
    "    This function uses the Google Static Maps API to download and save\n",
    "    one satellite image.\n",
    "    :param out_fn: Output filename for saved image\n",
    "    :param lat: Latitude of image center\n",
    "    :param lon: Longitude of image center\n",
    "    :param height: Height of image in pixels\n",
    "    :param width: Width of image in pixels\n",
    "    :param zoom: Zoom level of image\n",
    "    \"\"\"\n",
    "    # Google Static Maps API key\n",
    "    api_key = 'AIzaSyAejgapvGncLMRiMlUoqZ2h6yRF-lwNYMM'\n",
    "    \n",
    "    # Save satellite image\n",
    "    url_pattern = 'https://maps.googleapis.com/maps/api/staticmap?center=%0.6f,%0.6f&zoom=%s&size=%sx%s&maptype=satellite&key=%s'\n",
    "    url = url_pattern % (lat, lon, zoom, height, width, api_key)\n",
    "    urllib.urlretrieve(url, out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the function and make sure that we can save one image at a time at the desired location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a picture of Rains 214\n",
    "out_fn = '../images/practice/Rains214.png'\n",
    "lat = 37.421179\n",
    "lon = -122.157794\n",
    "sample_image(out_fn, lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function to sample many images from each DHS location. Our goal is to be able to sample multiple images (at random) from each DHS location, and store data about those images (which DHS cell id they match with, DHS cell longitude and latitude, image longitude and latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_dhs(image_data, cell_id, cell_lat, cell_lon, samples,\n",
    "               out_dir):\n",
    "    \"\"\"\n",
    "    This function samples multiple images at random for a DHS location\n",
    "    and saves them in the output directory.\n",
    "    :param image_data: DataFrame containing image metadata\n",
    "    :param cell_id: Cell ID of DHS location\n",
    "    :param cell_lat: Latitude of DHS location\n",
    "    :param cell_lon: Longitude of DHS location\n",
    "    :param samples: Number of samples to get\n",
    "    :param out_dir: Directory for sampled images\n",
    "    :returns: DataFrame containing updated image metadata\n",
    "    \"\"\"\n",
    "    t_start = time.time()\n",
    "    \n",
    "    # Sample images\n",
    "    for i in range(samples):\n",
    "        # Randomly sample within half-degree cell\n",
    "        lat = cell_lat + np.random.uniform(-0.25, 0.25)\n",
    "        lon = cell_lon + np.random.uniform(-0.25, 0.25)\n",
    "        # Determine output filename\n",
    "        fn = str(cell_id) + '_' + str(i) + '.png'\n",
    "        out_fn = out_dir + fn\n",
    "        # Save image\n",
    "        sample_image(out_fn, lat, lon)\n",
    "        # Update image metadata\n",
    "        temp_data = pd.DataFrame({'image': [fn], 'cellid': [cell_id],\n",
    "                                 'cell_lat': [cell_lat], 'cell_lon': \n",
    "                                 [cell_lon], 'lat': [lat], 'lon': \n",
    "                                 [lon]})\n",
    "        image_data = pd.concat([image_data, temp_data])\n",
    "    \n",
    "    # Return updated image metadata\n",
    "    t_end = time.time()\n",
    "    print 'Sampled {} images from DHS cell {} in {} seconds.'.format(\n",
    "                                                    samples, cell_id,\n",
    "                                                    (t_end - t_start))\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this out, let's get some samples from DHS locations specified in our DHS data csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 5 images from DHS cell 100498 in 1.73706912994 seconds.\n",
      "Sampled 5 images from DHS cell 101916 in 1.61488604546 seconds.\n",
      "Sampled 5 images from DHS cell 101940 in 1.67446708679 seconds.\n",
      "Sampled 5 images from DHS cell 101946 in 1.70053792 seconds.\n",
      "Sampled 5 images from DHS cell 101976 in 1.48707222939 seconds.\n",
      "Sampled 5 images from DHS cell 103383 in 1.59422588348 seconds.\n",
      "Sampled 5 images from DHS cell 104103 in 1.53859400749 seconds.\n",
      "Sampled 5 images from DHS cell 106271 in 1.61935305595 seconds.\n",
      "Sampled 5 images from DHS cell 106977 in 1.72392296791 seconds.\n",
      "Sampled 5 images from DHS cell 106991 in 1.68160200119 seconds.\n",
      "Sampled 5 images from DHS cell 109148 in 1.70569705963 seconds.\n",
      "Sampled 5 images from DHS cell 110577 in 2.10972499847 seconds.\n",
      "Sampled 5 images from DHS cell 110578 in 1.56889605522 seconds.\n",
      "Sampled 5 images from DHS cell 111296 in 1.81126403809 seconds.\n",
      "Sampled 5 images from DHS cell 111297 in 1.69076895714 seconds.\n",
      "Sampled 5 images from DHS cell 112736 in 1.67132902145 seconds.\n",
      "Sampled 5 images from DHS cell 119239 in 1.4114689827 seconds.\n",
      "Sampled 5 images from DHS cell 119959 in 1.26133012772 seconds.\n",
      "Sampled 5 images from DHS cell 123511 in 1.55576610565 seconds.\n",
      "Sampled 5 images from DHS cell 123560 in 1.06571793556 seconds.\n",
      "Sampled 5 images from DHS cell 124259 in 1.58482789993 seconds.\n",
      "Sampled 5 images from DHS cell 124979 in 1.61345696449 seconds.\n",
      "Sampled 5 images from DHS cell 126427 in 1.34682703018 seconds.\n",
      "Sampled 5 images from DHS cell 127100 in 1.21925210953 seconds.\n",
      "Sampled 5 images from DHS cell 127141 in 1.62888503075 seconds.\n",
      "Sampled 5 images from DHS cell 127859 in 1.61247301102 seconds.\n",
      "Sampled 5 images from DHS cell 127874 in 1.57941699028 seconds.\n",
      "Sampled 5 images from DHS cell 127875 in 1.59933114052 seconds.\n",
      "Sampled 5 images from DHS cell 128594 in 1.68098688126 seconds.\n",
      "Sampled 5 images from DHS cell 128595 in 1.63621997833 seconds.\n",
      "Sampled 5 images from DHS cell 129313 in 1.75761318207 seconds.\n",
      "Sampled 5 images from DHS cell 130746 in 1.47222495079 seconds.\n",
      "Sampled 5 images from DHS cell 135740 in 0.901402950287 seconds.\n",
      "Sampled 5 images from DHS cell 135744 in 1.23742890358 seconds.\n",
      "Sampled 5 images from DHS cell 136453 in 1.70195412636 seconds.\n",
      "Sampled 5 images from DHS cell 136454 in 1.5938179493 seconds.\n",
      "Sampled 5 images from DHS cell 136455 in 1.61844182014 seconds.\n",
      "Sampled 5 images from DHS cell 136456 in 1.50836706161 seconds.\n",
      "Sampled 5 images from DHS cell 136457 in 1.10275006294 seconds.\n",
      "Sampled 5 images from DHS cell 137152 in 1.64150595665 seconds.\n",
      "Sampled 5 images from DHS cell 137157 in 0.982125997543 seconds.\n",
      "Sampled 5 images from DHS cell 137172 in 1.13255095482 seconds.\n",
      "Sampled 5 images from DHS cell 137173 in 1.49979400635 seconds.\n",
      "Sampled 5 images from DHS cell 137174 in 1.59105801582 seconds.\n",
      "Sampled 5 images from DHS cell 137175 in 1.73971891403 seconds.\n",
      "Sampled 5 images from DHS cell 137176 in 1.60601305962 seconds.\n",
      "Sampled 5 images from DHS cell 137177 in 1.23462295532 seconds.\n",
      "Sampled 5 images from DHS cell 137879 in 1.60644197464 seconds.\n",
      "Sampled 5 images from DHS cell 137880 in 1.5980360508 seconds.\n",
      "Sampled 5 images from DHS cell 137892 in 1.61973714828 seconds.\n",
      "Sampled 5 images from DHS cell 137893 in 1.36553382874 seconds.\n",
      "Sampled 5 images from DHS cell 137894 in 1.67501282692 seconds.\n",
      "Sampled 5 images from DHS cell 137895 in 1.81306910515 seconds.\n",
      "Sampled 5 images from DHS cell 137896 in 1.71571612358 seconds.\n",
      "Sampled 5 images from DHS cell 138597 in 1.66637396812 seconds.\n",
      "Sampled 5 images from DHS cell 138599 in 1.62501215935 seconds.\n",
      "Sampled 5 images from DHS cell 138600 in 1.7176361084 seconds.\n",
      "Sampled 5 images from DHS cell 138602 in 1.66705989838 seconds.\n",
      "Sampled 5 images from DHS cell 138611 in 1.12000203133 seconds.\n",
      "Sampled 5 images from DHS cell 138612 in 1.56955099106 seconds.\n",
      "Sampled 5 images from DHS cell 138613 in 1.08639502525 seconds.\n",
      "Sampled 5 images from DHS cell 138614 in 1.69881987572 seconds.\n",
      "Sampled 5 images from DHS cell 138615 in 1.51109695435 seconds.\n",
      "Sampled 5 images from DHS cell 139317 in 1.78746294975 seconds.\n",
      "Sampled 5 images from DHS cell 139326 in 1.53257703781 seconds.\n",
      "Sampled 5 images from DHS cell 139327 in 1.69079494476 seconds.\n",
      "Sampled 5 images from DHS cell 139328 in 1.68545293808 seconds.\n",
      "Sampled 5 images from DHS cell 139329 in 1.47911000252 seconds.\n",
      "Sampled 5 images from DHS cell 139332 in 1.09537196159 seconds.\n",
      "Sampled 5 images from DHS cell 139333 in 1.40693616867 seconds.\n",
      "Sampled 5 images from DHS cell 139336 in 1.46758103371 seconds.\n",
      "Sampled 5 images from DHS cell 140030 in 1.38526010513 seconds.\n",
      "Sampled 5 images from DHS cell 140047 in 1.80243110657 seconds.\n",
      "Sampled 5 images from DHS cell 140048 in 1.62317299843 seconds.\n",
      "Sampled 5 images from DHS cell 140049 in 1.72296595573 seconds.\n",
      "Sampled 5 images from DHS cell 140051 in 1.70024204254 seconds.\n",
      "Sampled 5 images from DHS cell 140750 in 1.71876692772 seconds.\n",
      "Sampled 5 images from DHS cell 140769 in 1.63567996025 seconds.\n",
      "Sampled 5 images from DHS cell 140770 in 1.64097499847 seconds.\n",
      "Sampled 5 images from DHS cell 140771 in 1.73109817505 seconds.\n",
      "Sampled 5 images from DHS cell 140773 in 1.48209786415 seconds.\n",
      "Sampled 5 images from DHS cell 140774 in 1.63797187805 seconds.\n",
      "Sampled 5 images from DHS cell 141489 in 1.62829518318 seconds.\n",
      "Sampled 5 images from DHS cell 141490 in 1.65297698975 seconds.\n",
      "Sampled 5 images from DHS cell 142210 in 1.75781702995 seconds.\n",
      "Sampled 5 images from DHS cell 142935 in 1.59545588493 seconds.\n",
      "Sampled 5 images from DHS cell 142936 in 1.6350479126 seconds.\n",
      "Sampled 5 images from DHS cell 142946 in 1.54296684265 seconds.\n",
      "Sampled 5 images from DHS cell 142998 in 1.56703805923 seconds.\n",
      "Sampled 5 images from DHS cell 143613 in 1.51579999924 seconds.\n",
      "Sampled 5 images from DHS cell 143654 in 1.56528401375 seconds.\n",
      "Sampled 5 images from DHS cell 143666 in 1.68900418282 seconds.\n",
      "Sampled 5 images from DHS cell 143668 in 1.54364514351 seconds.\n",
      "Sampled 5 images from DHS cell 144379 in 1.65461277962 seconds.\n",
      "Sampled 5 images from DHS cell 145096 in 1.57660102844 seconds.\n",
      "Sampled 5 images from DHS cell 145816 in 1.61037707329 seconds.\n",
      "Sampled 5 images from DHS cell 147254 in 1.61574196815 seconds.\n",
      "Sampled 5 images from DHS cell 147258 in 1.56854009628 seconds.\n",
      "Sampled 5 images from DHS cell 147271 in 1.6405248642 seconds.\n",
      "Sampled 5 images from DHS cell 147944 in 1.58395314217 seconds.\n",
      "Done. Sample 500 images total.\n"
     ]
    }
   ],
   "source": [
    "# Import and preview csv data\n",
    "dhs_fn = '../data/IMR1990-2000_NL1992-2012_thresh100.csv'\n",
    "dhs_data = pd.read_csv(dhs_fn)\n",
    "\n",
    "# Samples to take from each location\n",
    "samples = 5\n",
    "# Number of locations to sample from\n",
    "locations = 100\n",
    "\n",
    "# Output image directory\n",
    "out_dir = '../images/practice/in/'\n",
    "out_csv = '../data/dhs_image_metadata.csv'\n",
    "\n",
    "# Create DataFrame for image metadata\n",
    "image_data = pd.DataFrame(columns=['image', 'cellid', 'cell_lat',\n",
    "                                  'cell_lon', 'lat', 'lon'])\n",
    "\n",
    "# Sampling images from DHS locations\n",
    "for index, row in dhs_data.iterrows():\n",
    "    if index + 1 > locations:\n",
    "        break\n",
    "    \n",
    "    cell_id = int(row['cellid'])\n",
    "    cell_lat = row['lat']\n",
    "    cell_lon = row['lon']\n",
    "    # Sample images\n",
    "    image_data = sample_dhs(image_data, cell_id, cell_lat, cell_lon,\n",
    "                           samples, out_dir)\n",
    "\n",
    "# Save image metadata to csv\n",
    "image_data.set_index('image', inplace=True)\n",
    "image_data.to_csv(out_csv)\n",
    "\n",
    "print 'Done. Sample {} images total.'.format(samples * locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to batch classify these practice images using the two-step batch classification function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/afs/cs.stanford.edu/u/nealjean/.local/lib/python2.7/site-packages/sklearn']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classify import *\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 500 images in 15.0758049488 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Rename images first\n",
    "in_dir = '../images/practice/in/'\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for image_fn in glob.glob(in_dir + '*'):\n",
    "    image = cv2.imread(image_fn)\n",
    "    out_fn = in_dir + str(count) + '.png'\n",
    "    cv2.imwrite(out_fn, image)\n",
    "    count += 1\n",
    "t1 = time.time()\n",
    "print 'Renamed {} images in {} seconds.'.format(count, (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch classify parameters\n",
    "out_dir = '../images/practice/out/'\n",
    "template_fn = '../images/templates/template1.png'\n",
    "image_data_fn = '../data/all_image_data.csv'\n",
    "hog_data_fn = '../data/hog_training_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified 500 images in 211.244637012 seconds.\n"
     ]
    }
   ],
   "source": [
    "two_step_batch_classify(in_dir, out_dir, template_fn, image_data_fn,\n",
    "                       hog_data_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This two-step classification test worked better than the simple color histogram classifier from earlier, but definitely not as well as on the original DHS image set (as expected, since the training data was taken from that set).\n",
    "\n",
    "Let's repeat this process to get a lot more training samples for the random forest classifier, then test again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Idea: Use Random Forests for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_in = '../data/hog_training_data.csv'\n",
    "(features, colors, hogs, mags, labels, label_encoder) = \\\n",
    "            import_image_data(csv_in, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 73)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mix up the data\n",
    "perm = np.random.permutation(labels.size)\n",
    "features = features[perm]\n",
    "labels = labels[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification accuracy: 0.964285714286\n"
     ]
    }
   ],
   "source": [
    "forest = ensemble.RandomForestClassifier(random_state=0,\n",
    "                                        class_weight='auto')\n",
    "# Training on training examples\n",
    "forest.fit(features[:300], labels[:300])\n",
    "accuracy = forest.score(features[300:], labels[300:])\n",
    "print 'Overall classification accuracy: {}'.format(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the samples that I collected from the image patches that the color histogram found as roofs, it seems that using random forests to classify image patches might work pretty well.\n",
    "\n",
    "The next thing that I will try will be to divide my 400x400 pixel satellite images into 25 80x80 patches, and then use random forests to try to classify them into building and non-building categories. Using this strategy, I can also use the built-in HOG functions, which will probably be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
